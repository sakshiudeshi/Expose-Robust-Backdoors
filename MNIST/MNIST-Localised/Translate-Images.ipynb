{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST-Backdoored-Localised\n",
    "### Image Translation\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.optim import *\n",
    "from cox.utils import Parameters\n",
    "\n",
    "from robustness import model_utils, datasets, train, defaults\n",
    "from robustness.model_utils import make_and_restore_model\n",
    "from DatasetsNew import MNIST\n",
    "\n",
    "import cox.store\n",
    "import torch as ch\n",
    "import DatasetsNew\n",
    "import defaultsNew\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "\n",
    "from label_maps import CLASS_DICT\n",
    "from user_constants import DATA_PATH_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'MNIST' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset mnist..\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_function = getattr(DatasetsNew, 'MNIST')\n",
    "DATA_PATH_DICT[DATA]\n",
    "dataset = dataset_function(DATA_PATH_DICT[DATA])\n",
    "_, test_loader = dataset.make_loaders(workers=NUM_WORKERS,\n",
    "                                      batch_size=BATCH_SIZE, \n",
    "                                      data_aug=False)\n",
    "data_iterator = enumerate(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models/MNIST_Localised_100_epochs_checkpoint.pt.best'\n",
      "=> loaded checkpoint 'models/MNIST_Localised_100_epochs_checkpoint.pt.best' (epoch 51)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_backdoored, _ = make_and_restore_model(arch='resnet18', dataset=dataset,resume_path='models/MNIST_Localised_100_epochs_checkpoint.pt.best',parallel=False) \n",
    "model_backdoored.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (imgs, label) = next(enumerate(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "        #'criterion': ch.nn.CrossEntropyLoss(reduction='none'),\n",
    "        'constraint':'2',\n",
    "        'eps': 100,\n",
    "        'step_size': 0.25,\n",
    "        'iterations': 75,\n",
    "        'do_tqdm': True,\n",
    "        'targeted': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation for Local Backdoored model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset mnist..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 0.007984926924109459: 100%|██████████| 75/75 [00:04<00:00, 18.33it/s]\n",
      "Current loss: 0.0004926204564981163: 100%|██████████| 75/75 [00:03<00:00, 19.69it/s]\n",
      "Current loss: 0.008436398580670357: 100%|██████████| 75/75 [00:03<00:00, 19.74it/s]\n",
      "Current loss: 0.005663611926138401: 100%|██████████| 75/75 [00:03<00:00, 19.19it/s]\n",
      "Current loss: 0.0007116174674592912: 100%|██████████| 75/75 [00:03<00:00, 19.70it/s]\n",
      "Current loss: 9.08124828338623:   4%|▍         | 3/75 [00:00<00:03, 20.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "saved:  saved_pickles/backdoored-model-img-translated/img_translated_from_dataset_0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 6.604194641113281e-05: 100%|██████████| 75/75 [00:03<00:00, 19.68it/s] \n",
      "Current loss: 6.120204488979653e-05: 100%|██████████| 75/75 [00:03<00:00, 19.34it/s] \n",
      "Current loss: 2.2392272512661293e-05: 100%|██████████| 75/75 [00:04<00:00, 18.34it/s]\n",
      "Current loss: 3.281593308201991e-05: 100%|██████████| 75/75 [00:03<00:00, 19.36it/s] \n",
      "Current loss: 0.00010327339259674773: 100%|██████████| 75/75 [00:04<00:00, 18.43it/s]\n",
      "Current loss: 9.632402420043945:   3%|▎         | 2/75 [00:00<00:03, 19.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "saved:  saved_pickles/backdoored-model-img-translated/img_translated_from_dataset_1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 4.863738922722405e-06: 100%|██████████| 75/75 [00:03<00:00, 18.90it/s] \n",
      "Current loss: 4.806518518307712e-06: 100%|██████████| 75/75 [00:03<00:00, 18.82it/s] \n",
      "Current loss: 1.029968279908644e-05: 100%|██████████| 75/75 [00:03<00:00, 19.04it/s] \n",
      "Current loss: 3.929138074454386e-06: 100%|██████████| 75/75 [00:03<00:00, 19.33it/s] \n",
      "Current loss: 4.796981556864921e-06: 100%|██████████| 75/75 [00:03<00:00, 19.35it/s] \n",
      "Current loss: 9.194746017456055:   4%|▍         | 3/75 [00:00<00:03, 20.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "saved:  saved_pickles/backdoored-model-img-translated/img_translated_from_dataset_2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 1.6212463549436507e-07: 100%|██████████| 75/75 [00:03<00:00, 19.79it/s]\n",
      "Current loss: 1.6212463549436507e-07: 100%|██████████| 75/75 [00:03<00:00, 19.76it/s]\n",
      "Current loss: 1.5258788721439487e-07: 100%|██████████| 75/75 [00:03<00:00, 19.72it/s]\n",
      "Current loss: 1.9073485191256623e-07: 100%|██████████| 75/75 [00:03<00:00, 19.77it/s]\n",
      "Current loss: 1.5258788721439487e-07: 100%|██████████| 75/75 [00:03<00:00, 19.75it/s]\n",
      "Current loss: 9.311416625976562:   4%|▍         | 3/75 [00:00<00:03, 20.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "saved:  saved_pickles/backdoored-model-img-translated/img_translated_from_dataset_3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 1.1568069567147177e-05: 100%|██████████| 75/75 [00:03<00:00, 19.73it/s]\n",
      "Current loss: 1.6231537301791832e-05: 100%|██████████| 75/75 [00:03<00:00, 19.79it/s]\n",
      "Current loss: 1.569747837493196e-05: 100%|██████████| 75/75 [00:03<00:00, 19.48it/s] \n",
      "Current loss: 1.9922255887649953e-05: 100%|██████████| 75/75 [00:03<00:00, 18.98it/s]\n",
      "Current loss: 2.1524429030250758e-05: 100%|██████████| 75/75 [00:03<00:00, 19.27it/s]\n",
      "Current loss: 9.044426918029785:   3%|▎         | 2/75 [00:00<00:03, 19.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "saved:  saved_pickles/backdoored-model-img-translated/img_translated_from_dataset_4.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 3.395080511836568e-06: 100%|██████████| 75/75 [00:03<00:00, 19.34it/s] \n",
      "Current loss: 2.3078916910890257e-06: 100%|██████████| 75/75 [00:04<00:00, 18.61it/s]\n",
      "Current loss: 4.739761152450228e-06: 100%|██████████| 75/75 [00:03<00:00, 19.36it/s] \n",
      "Current loss: 1.3351440202313825e-06: 100%|██████████| 75/75 [00:03<00:00, 19.78it/s]\n",
      "Current loss: 5.111694008519407e-06: 100%|██████████| 75/75 [00:03<00:00, 19.61it/s] \n",
      "Current loss: 8.769858360290527:   4%|▍         | 3/75 [00:00<00:03, 19.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "saved:  saved_pickles/backdoored-model-img-translated/img_translated_from_dataset_5.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 0.00023915289784781635: 100%|██████████| 75/75 [00:03<00:00, 19.57it/s]\n",
      "Current loss: 8.131026697810739e-05: 100%|██████████| 75/75 [00:03<00:00, 19.67it/s] \n",
      "Current loss: 5.555152893066406e-05: 100%|██████████| 75/75 [00:03<00:00, 19.72it/s] \n",
      "Current loss: 0.0005462359986267984: 100%|██████████| 75/75 [00:03<00:00, 19.66it/s]\n",
      "Current loss: 9.763240814208984e-05: 100%|██████████| 75/75 [00:03<00:00, 19.74it/s] \n",
      "Current loss: 7.996007919311523:   3%|▎         | 2/75 [00:00<00:03, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "saved:  saved_pickles/backdoored-model-img-translated/img_translated_from_dataset_6.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 4.768371297814156e-08: 100%|██████████| 75/75 [00:03<00:00, 19.77it/s] \n",
      "Current loss: 9.53674295089968e-09: 100%|██████████| 75/75 [00:03<00:00, 19.70it/s]  \n",
      "Current loss: 0.0: 100%|██████████| 75/75 [00:03<00:00, 19.59it/s]                   \n",
      "Current loss: 9.53674295089968e-09: 100%|██████████| 75/75 [00:03<00:00, 19.75it/s]  \n",
      "Current loss: 2.8610228852699038e-08: 100%|██████████| 75/75 [00:03<00:00, 19.70it/s]\n",
      "Current loss: 9.41772174835205:   4%|▍         | 3/75 [00:00<00:03, 20.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "saved:  saved_pickles/backdoored-model-img-translated/img_translated_from_dataset_8.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 0.000555815699044615: 100%|██████████| 75/75 [00:03<00:00, 19.70it/s] \n",
      "Current loss: 0.00011024951527360827: 100%|██████████| 75/75 [00:03<00:00, 19.73it/s]\n",
      "Current loss: 0.00015473365783691406: 100%|██████████| 75/75 [00:03<00:00, 19.73it/s]\n",
      "Current loss: 7.472038123523816e-05: 100%|██████████| 75/75 [00:03<00:00, 19.68it/s] \n",
      "Current loss: 0.00012014865933451802: 100%|██████████| 75/75 [00:03<00:00, 19.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28])\n",
      "saved:  saved_pickles/backdoored-model-img-translated/img_translated_from_dataset_9.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_, train_loader = dataset.make_loaders(workers=NUM_WORKERS, batch_size=BATCH_SIZE)\n",
    "_, (imgs, label) = next(enumerate(train_loader))\n",
    "\n",
    "# for targ_lbl in range(10):\n",
    "for targ_lbl in [0, 1, 2, 3, 4, 5, 6, 8, 9]:\n",
    "# for targ_lbl in [7]:\n",
    "    targ = []\n",
    "\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        targ.append(targ_lbl)\n",
    "    targ = ch.tensor(targ)\n",
    "\n",
    "    _, img_translated = model_backdoored(imgs.cuda(), targ.cuda(), make_adv=True, **kwargs)\n",
    "\n",
    "    for i in range(4):\n",
    "        _, (imgs, label) = next(enumerate(train_loader))\n",
    "        targ = []\n",
    "        for i in range(BATCH_SIZE):\n",
    "            targ.append(targ_lbl)\n",
    "        targ = ch.tensor(targ)\n",
    "\n",
    "        _, img_translated_new = model_backdoored(imgs.cuda(), targ.cuda(), make_adv=True, **kwargs)\n",
    "        img_translated = ch.cat((img_translated, img_translated_new), 0)\n",
    "    #     clean_img_ch = ch.cat((clean_img_ch, imgs[i].reshape(1,3,32,32)), 0)\n",
    "\n",
    "    print(img_translated.size())\n",
    "    \n",
    "    \n",
    "    filename = \"saved_pickles/backdoored-model-img-translated/img_translated_from_dataset_\" + str(targ_lbl) + \".pkl\"\n",
    "    \n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(img_translated, handle)\n",
    "    print(\"saved: \", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
